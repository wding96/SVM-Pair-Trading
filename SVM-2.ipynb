{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" CITATION\n",
    "@article{scikit-learn,\n",
    " title={Scikit-learn: Machine Learning in {P}ython},\n",
    " author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.\n",
    "         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.\n",
    "         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and\n",
    "         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},\n",
    " journal={Journal of Machine Learning Research},\n",
    " volume={12},\n",
    " pages={2825--2830},\n",
    " year={2011}\n",
    "}\n",
    "\n",
    "https://towardsdatascience.com/intro-to-support-vector-machines-with-a-trading-example-1d4a7997ced6\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "## Install Homebrew and then install TA-lib, for RSI calculation\n",
    "import talib as ta\n",
    "from talib import MA_Type\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.DataFrame(pd.read_csv('/Users/chico_mua/Desktop/MFE ML/Project/sig_output_4.csv'))\n",
    "raw_data = raw_data.drop(['Unnamed: 0','ind','X','permno','siccd','shrcls','dlret','close','ret','vol',\n",
    "                         'WMA','MFI','RSI','Liq','retx','low','high','SMA'],1)\n",
    "Ticker_List = raw_data['ticker'].unique().tolist()\n",
    "ind_list = raw_data['industry'].unique().tolist()\n",
    "\n",
    "# unk_index = raw_data[raw_data['industry'] == 'UNK'].index\n",
    "# raw_data.loc[unk_index[0]:unk_index[-1],'industry'] = 'Aircraft'\n",
    "\n",
    "# ind_list = raw_data['industry'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signa_data = raw_data[['']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Condition of Trading Signal \n",
    "for i in Ticker_List:\n",
    "    Stock_Data = raw_data[raw_data['ticker'] == i]\n",
    "    Signal_List = []\n",
    "    for j in Stock_Data[i]['Returns']:\n",
    "        \n",
    "        if (j>=0):\n",
    "            Signal_List.append(\"1\")\n",
    "            \n",
    "        else:\n",
    "            Signal_List.append(\"0\")\n",
    "            \n",
    "    Stock_Data[i]['Signal'] = Signal_List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data be normalized\n",
    "## scales each feature by its maximum absolute valu3\n",
    "max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "\n",
    "Model_Dict = {}\n",
    "\n",
    "## \n",
    "date_time_str = '20190101'\n",
    "split_date = datetime.datetime.strptime(date_time_str, '%Y%m%d')\n",
    "\n",
    "for i in Ticker_List:\n",
    "    Stock_Data = raw_data[raw_data['ticker'] == i]\n",
    "    \n",
    "    X = np.array(Stock_Data[i].drop(['Signal','Returns'],1))\n",
    "    X = max_abs_scaler.fit_transform(X)\n",
    "    Y = np.array(Stock_Data[i]['Signal'])\n",
    "   \n",
    "    \"\"\"\n",
    "    split test & train data\n",
    "    \n",
    "    ## X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "    X_sample = X[X['date'] < split_date]\n",
    "    y_sample = Y[Y['date'] < split_date]\n",
    "    \n",
    "    X_out_of_sample = X[X['date'] > split_date]\n",
    "    y_out_of_sample = Y[Y['date'] > split_date]\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\"\n",
    "    Cross Validation\n",
    "    \n",
    "    Citation:  https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "                    \n",
    "    scoring = {'prec_macro': 'precision_macro',\n",
    "               'rec_macro': make_scorer(recall_score, average='macro')}\n",
    "    \n",
    "    clf \n",
    "    scores = cross_validate(clf, X_sample, y_sample, scoring=scoring, cv=5, return_train_score=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    sorted(scores.keys())\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    scores['train_rec_macro']\n",
    "    \n",
    "    Model_Dict[i] = {} #Model_Dict: dict of dict\n",
    "    Model_Dict[i]['X Train'] = X_sample #key: X Train, value = X_train\n",
    "    Model_Dict[i]['X Test'] = X_test\n",
    "    Model_Dict[i]['Y Train'] = y_sample\n",
    "    Model_Dict[i]['Y Test'] = y_test\n",
    "    \n",
    "    model = svm.SVC(kernel='rbf',decision_function_shape='ovo')\n",
    "    #model = svm.SVC(kernel='linear')\n",
    "    #model = svm.SVC(kernel='linear',decision_function_shape='ovo')\n",
    "    #model = svm.SVC(kernel='rbf',decision_function_shape='ovo')\n",
    "    #model = svm.SVC(kernel='poly')\n",
    "    #model = svm.SVC(kernel='poly',decision_function_shape='ovo')\n",
    "    #model = svm.SVC(kernel='sigmoid')\n",
    "    #model = svm.SVC(kernel='sigmoid',decision_function_shape='ovo')\n",
    "    \n",
    "    model.fit(Model_Dict[i]['X Train'], Model_Dict[i]['Y Train'])\n",
    "    y_pred = model.predict(Model_Dict[i]['X Test'])\n",
    "    \n",
    "    Model_Dict[i]['Y Prediction'] = y_pred\n",
    "    \n",
    "    #print(\"SVM Model Info for Ticker: \"+i)\n",
    "    \n",
    "    #print(\"Accuracy:\",metrics.accuracy_score(Model_Dict[i]['Y Test'], Model_Dict[i]['Y Prediction']))\n",
    "    Model_Dict[i]['Accuracy'] = metrics.accuracy_score(Model_Dict[i]['Y Test'], Model_Dict[i]['Y Prediction'])\n",
    "    \n",
    "    #print(\"Precision:\",metrics.precision_score(Model_Dict[i]['Y Test'], Model_Dict[i]['Y Prediction'],pos_label=str(1),average=\"macro\"))\n",
    "    Model_Dict[i]['Precision'] = metrics.precision_score(Model_Dict[i]['Y Test'], Model_Dict[i]['Y Prediction'],pos_label=str(1),average=\"macro\")\n",
    "    \n",
    "    #print(\"Recall:\",metrics.recall_score(Model_Dict[i]['Y Test'], Model_Dict[i]['Y Prediction'],pos_label=str(1),average=\"macro\"))\n",
    "    Model_Dict[i]['Recall'] = metrics.recall_score(Model_Dict[i]['Y Test'], Model_Dict[i]['Y Prediction'],pos_label=str(1),average=\"macro\")\n",
    "    \n",
    "    #print(\"#################### \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Ticker_List:\n",
    "    \n",
    "    prediction_length = len(Model_Dict[i]['Y Prediction'])\n",
    "    \n",
    "    Stock_Data[i]['SVM Signal'] = 0\n",
    "    Stock_Data[i]['SVM Returns'] = 0\n",
    "    Stock_Data[i]['Total Strat Returns'] = 0\n",
    "    Stock_Data[i]['Market Returns'] = 0\n",
    "    \n",
    "    Signal_Column = Stock_Data[i].columns.get_loc('SVM Signal') # return column index\n",
    "    Strat_Column = Stock_Data[i].columns.get_loc('SVM Returns')\n",
    "    Return_Column = Stock_Data[i].columns.get_loc('Total Strat Returns')\n",
    "    Market_Column = Stock_Data[i].columns.get_loc('Market Returns')\n",
    "       \n",
    "    Stock_Data[i].iloc[-prediction_length:, Signal_Column] = list(map(int, Model_Dict[i]['Y Prediction']))\n",
    "    Stock_Data[i]['SVM Returns'] = Stock_Data[i]['SVM Signal'] * Stock_Data[i]['Returns'].shift(-1)\n",
    "    # pair trading recumulative return\n",
    "    Stock_Data[i].iloc[-prediction_length:,Return_Column] = np.nancumsum(Stock_Data[i]['SVM Returns'][-prediction_length:])\n",
    "    # benchmark\n",
    "    Stock_Data[i].iloc[-prediction_length:,Market_Column] = np.nancumsum(Stock_Data[i]['Returns'][-prediction_length:])\n",
    "    \n",
    "    Model_Dict[i]['Sharpe_Ratio'] = (Stock_Data[i]['Total Strat Returns'][-1] - Stock_Data[i]['Market Returns'][-1])/ \\\n",
    "                    np.nanstd(Stock_Data[i]['Total Strat Returns'][-prediction_length:])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
